# -*- coding: utf-8 -*-
"""Lab1 PyTorch and ANNs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/141qV-yDuqSEFgh3xa3KXlErwp1bJh-BF

# Lab 1. PyTorch and ANNs

This lab is a warm up to get you used to the PyTorch programming environment used
in the course, and also to help you review and renew your knowledge
of Python and relevant Python libraries.
The lab must be done individually. Please recall that the
University of Toronto plagarism rules apply.

By the end of this lab, you should be able to:

1. Be able to perform basic PyTorch tensor operations.
2. Be able to load data into PyTorch
3. Be able to configure an Artificial Neural Network (ANN) using PyTorch
4. Be able to train ANNs using PyTorch
5. Be able to evaluate different ANN configuations

You will need to use numpy and PyTorch documentations for this assignment:

* https://docs.scipy.org/doc/numpy/reference/
* https://pytorch.org/docs/stable/torch.html

You can also reference Python API documentations freely.


### What to submit

Submit a PDF file containing all your code, outputs, and write-up
from parts 1-5. You can produce a PDF of your Google Colab file by
going to `File -> Print` and then save as PDF. The Colab instructions
has more information.

**Do not submit any other files produced by your code.**

Include a link to your colab file in your submission.

Please use Google Colab to complete this assignment. If you want to use Jupyter Notebook, please complete the assignment and upload your Jupyter Notebook file to Google Colab for submission.

**Adjust the scaling to ensure that the text is not cutoff at the margins.**

## Colab Link

Submit make sure to include a link to your colab file here

Colab Link: https://colab.research.google.com/drive/141qV-yDuqSEFgh3xa3KXlErwp1bJh-BF?usp=sharing

## Part 1. Python Basics [3 pt]

The purpose of this section is to get you used to the
basics of Python, including working with functions, numbers,
lists, and strings.

Note that we **will** be checking your code for clarity and efficiency.

If you have trouble with this part of the assignment, please review http://cs231n.github.io/python-numpy-tutorial/

### Part (a) -- 1pt

Write a function `sum_of_cubes` that computes the sum of cubes up to `n`. If the input to `sum_of_cubes` invalid (e.g. negative or non-integer `n`), the function should print out `"Invalid input"` and return `-1`.
"""

def sum_of_cubes(n):
    """Return the sum (1^3 + 2^3 + 3^3 + ... + n^3)

    Precondition: n > 0, type(n) == int

    >>> sum_of_cubes(3)
    36
    >>> sum_of_cubes(1)
    1
    """
    if type(n) != int or n < 0:
        print("Invalid input")
        return -1

    total = 0
    for i in range(n + 1):
        total += i ** 3
    return total

"""### Part (b) -- 1pt

Write a function `word_lengths` that takes a sentence (string), computes the length of each word in that sentence, and returns the length of each word in a list. You can
assume that words are always separated by a space character `" "`.

Hint: recall the `str.split` function in Python.
If you arenot sure how this function works, try
typing `help(str.split)` into a Python shell, or check out https://docs.python.org/3.6/library/stdtypes.html#str.split
"""

help(str.split)

def word_lengths(sentence):
    """Return a list containing the length of each word in
    sentence.

    >>> word_lengths("welcome to APS360!")
    [7, 2, 7]
    >>> word_lengths("machine learning is so cool")
    [7, 8, 2, 2, 4]
    """
    words = sentence.split(" ")
    lengths = []
    for word in words:
      lengths.append(len(word))
    return lengths

"""### Part (c) -- 1pt

Write a function `all_same_length` that takes a sentence (string),
and checks whether every word in the string is the same length.
You should call the function `word_lengths` in the body
of this new function.

"""

def all_same_length(sentence):
    """Return True if every word in sentence has the same
    length, and False otherwise.

    >>> all_same_length("all same length")
    False
    >>> word_lengths("hello world")
    True
    """
    lengths = word_lengths(sentence)
    for length in lengths:
      if length != lengths[0]:
        return False
    return True

"""## Part 2. NumPy Exercises [5 pt]

In this part of the assignment, you'll be manipulating arrays
usign NumPy. Normally, we use the shorter name `np` to represent
the package `numpy`.
"""

import numpy as np

"""### Part (a) -- 1pt

The below variables `matrix` and `vector` are numpy arrays. Explain what you think `<NumpyArray>.size` and `<NumpyArray>.shape` represent.
"""

matrix = np.array([[1., 2., 3., 0.5],
                   [4., 5., 0., 0.],
                   [-1., -2., 1., 1.]])
vector = np.array([2., 0., 1., -2.])

matrix.size

matrix.shape

vector.size

vector.shape

"""NumpyArray.size represents the total number of elements in the array.
NumpyArray.shape returns a tuple representing the dimensions of the array.

### Part (b) -- 1pt

Perform matrix multiplication `output = matrix x vector` by using
for loops to iterate through the columns and rows.
Do not use any builtin NumPy functions.
Cast your output into a NumPy array, if it isn't one already.

Hint: be mindful of the dimension of output
"""

output = None

def matrix_mult(matrix, vector):
    result = []
    for i in range(len(matrix)):
      sum_result = 0
      for j in range(len(vector)):
        sum_result += matrix[i][j] * vector[j]
      result.append(sum_result)
    return np.array(result)

output = matrix_mult(matrix, vector)

"""### Part (c) -- 1pt

Perform matrix multiplication `output2 = matrix x vector` by using
the function `numpy.dot`.

We will never actually write code as in
part(c), not only because `numpy.dot` is more concise and easier to read/write, but also performance-wise `numpy.dot` is much faster (it is written in C and highly optimized).
In general, we will avoid for loops in our code.
"""

output2 = None

output2 = np.dot(matrix, vector)

"""### Part (d) -- 1pt

As a way to test for consistency, show that the two outputs match.
"""

output_match = np.array_equal(output, output2)
output_match

"""### Part (e) -- 1pt

Show that using `np.dot` is faster than using your code from part (c).

You may find the below code snippit helpful:
"""

import time

# record the time before running code
start_time = time.time()

# place code to run here
for i in range(10000):
    99*99

# record the time after the code is run
end_time = time.time()

# compute the difference
diff = end_time - start_time
diff

def measure_run_time(function, matrix, vector):
    start = time.time()
    function(matrix, vector)
    end = time.time()
    diff = end - start
    return diff

measure_run_time(matrix_mult,matrix,vector)

measure_run_time(np.dot,matrix,vector)

"""## Part 3. Images [6 pt]

A picture or image can be represented as a NumPy array of “pixels”,
with dimensions H × W × C, where H is the height of the image, W is the width of the image,
and C is the number of colour channels. Typically we will use an image with channels that give the the Red, Green, and Blue “level” of each pixel, which is referred to with the short form RGB.

You will write Python code to load an image, and perform several array manipulations to the image and visualize their effects.
"""

import matplotlib.pyplot as plt

"""### Part (a) -- 1 pt

This is a photograph of a dog whose name is Mochi.

![alt text](https://drive.google.com/uc?export=view&id=1oaLVR2hr1_qzpKQ47i9rVUIklwbDcews)

Load the image from its url (https://drive.google.com/uc?export=view&id=1oaLVR2hr1_qzpKQ47i9rVUIklwbDcews) into the variable `img` using the `plt.imread` function.

Hint: You can enter the URL directly into the `plt.imread` function as a Python string.
"""

img = None

!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1oaLVR2hr1_qzpKQ47i9rVUIklwbDcews' -O 'image.jpg'

img = plt.imread("image.jpg")

"""### Part (b) -- 1pt

Use the function `plt.imshow` to visualize `img`.

This function will also show the coordinate system used to identify pixels.
The origin is at the top left corner, and the first dimension indicates the Y (row) direction,
and the second dimension indicates the X (column) dimension.
"""

plt.imshow(img)

"""### Part (c) -- 2pt

Modify the image by adding a constant value of 0.25 to each pixel in the `img` and
store the result in the variable `img_add`. Note that, since the range for the pixels
needs to be between [0, 1], you will also need to clip img_add to be in the range [0, 1]
using `numpy.clip`. Clipping sets any value that is outside of the desired range to the
closest endpoint. Display the image using `plt.imshow`.
"""

img_add = img + 0.25
img_add = np.clip(img_add, 0, 1)
plt.imshow(img_add)

"""### Part (d) -- 2pt

Crop the **original** image (`img` variable) to a 130 x 150 image including Mochi's face. Discard the alpha colour channel (i.e. resulting `img_cropped` should **only have RGB channels**)

Display the image.
"""

img_cropped = img[0:130, 0:150, 0:3]
plt.imshow(img_cropped)

"""## Part 4. Basics of PyTorch [6 pt]

PyTorch is a Python-based neural networks package. Along with tensorflow, PyTorch is currently one of the most popular machine learning libraries.

PyTorch, at its core, is similar to Numpy in a sense that they both
try to make it easier to write codes for scientific computing
achieve improved performance over vanilla Python by leveraging highly optimized C back-end.
However, compare to Numpy, PyTorch offers much better GPU support and provides many high-level features for machine learning. Technically, Numpy can be used to perform almost every thing PyTorch does. However, Numpy would be a lot slower than PyTorch, especially with CUDA GPU, and it would take more effort to write machine learning related code compared to using PyTorch.
"""

import torch

"""### Part (a) -- 1 pt

Use the function `torch.from_numpy` to convert the numpy array `img_cropped` into
a PyTorch tensor. Save the result in a variable called `img_torch`.
"""

img_torch = torch.from_numpy(img_cropped)

"""### Part (b) -- 1pt

Use the method `<Tensor>.shape` to find the shape (dimension and size) of `img_torch`.
"""

tensor_shape = img_torch.shape
print(tensor_shape)

"""### Part (c) -- 1pt

How many floating-point numbers are stored in the tensor `img_torch`?
"""

num_elements = torch.numel(img_torch)
print(num_elements)

"""### Part (d) -- 1 pt

What does the code `img_torch.transpose(0,2)` do? What does the expression return?
Is the original variable `img_torch` updated? Explain.
"""

print(img_torch.shape)
img_torch.transpose(0,2)
print(img_torch.transpose(0,2).shape)
print(img_torch.shape)

"""The code img_torch.transpose(0, 2) performs a transpose operation on the PyTorch tensor img_torch. Specifically, it swaps the dimensions at indices 0 and 2 while keeping the other dimensions unchanged. The original variable img_torch remains unchanged. The transpose() operation returns a new tensor with the desired permutation, but it does not modify the original tensor in-place.

### Part (e) -- 1 pt

What does the code `img_torch.unsqueeze(0)` do? What does the expression return?
Is the original variable `img_torch` updated? Explain.
"""

print(img_torch.shape)
img_torch.unsqueeze(0)
print(img_torch.unsqueeze(0).shape)
print(img_torch.shape)

"""The code img_torch.unsqueeze(0) adds a new dimension at the beginning of the PyTorch tensor img_torch. It returns a new tensor with the added dimension, but it does not modify the original tensor img_torch in-place. The shape of the new tensor will have a size of 1 in the added dimension.

### Part (f) -- 1 pt

Find the maximum value of `img_torch` along each colour channel? Your output should be a one-dimensional
PyTorch tensor with exactly three values.

Hint: lookup the function `torch.max`.
"""

torch.max(torch.max(img_torch, 1)[0], 0)[0]

"""## Part 5. Training an ANN [10 pt]

The sample code provided below is a 2-layer ANN trained on the MNIST dataset to identify digits less than 3 or greater than and equal to 3. Modify the code by changing any of the following and observe how the accuracy and error are affected:

- number of training iterations
- number of hidden units
- numbers of layers
- types of activation functions
- learning rate

Please select at least three different options from the list above. For each option, please select two to three different parameters and provide a table.

"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
import matplotlib.pyplot as plt # for plotting
import torch.optim as optim

torch.manual_seed(1) # set the random seed

# define a 2-layer artificial neural network
class Pigeon(nn.Module):
    def __init__(self):
        super(Pigeon, self).__init__()
        self.layer1 = nn.Linear(28 * 28, 30)
        self.layer2 = nn.Linear(30, 1)
    def forward(self, img):
        flattened = img.view(-1, 28 * 28)
        activation1 = self.layer1(flattened)
        activation1 = F.relu(activation1)
        activation2 = self.layer2(activation1)
        return activation2

pigeon = Pigeon()

# load the data
mnist_data = datasets.MNIST('data', train=True, download=True)
mnist_data = list(mnist_data)
mnist_train = mnist_data[:1000]
mnist_val   = mnist_data[1000:2000]
img_to_tensor = transforms.ToTensor()


# simplified training code to train `pigeon` on the "small digit recognition" task
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.SGD(pigeon.parameters(), lr=0.005, momentum=0.9)

num_epochs = 1
for epoch in range(num_epochs):
  for (image, label) in mnist_train:
      # actual ground truth: is the digit less than 3?
      actual = torch.tensor(label < 3).reshape([1,1]).type(torch.FloatTensor)
      # pigeon prediction
      out = pigeon(img_to_tensor(image)) # step 1-2
      # update the parameters based on the loss
      loss = criterion(out, actual)      # step 3
      loss.backward()                    # step 4 (compute the updates for each parameter)
      optimizer.step()                   # step 4 (make the updates for each parameter)
      optimizer.zero_grad()              # a clean up step for PyTorch

# computing the error and accuracy on the training set
error = 0
for (image, label) in mnist_train:
    prob = torch.sigmoid(pigeon(img_to_tensor(image)))
    if (prob < 0.5 and label < 3) or (prob >= 0.5 and label >= 3):
        error += 1
print("Training Error Rate:", error/len(mnist_train))
print("Training Accuracy:", 1 - error/len(mnist_train))


# computing the error and accuracy on a test set
error = 0
for (image, label) in mnist_val:
    prob = torch.sigmoid(pigeon(img_to_tensor(image)))
    if (prob < 0.5 and label < 3) or (prob >= 0.5 and label >= 3):
        error += 1
print("Test Error Rate:", error/len(mnist_val))
print("Test Accuracy:", 1 - error/len(mnist_val))

"""Original:
Training Error Rate: 0.036
Training Accuracy: 0.964
Test Error Rate: 0.079
Test Accuracy: 0.921
"""

import pandas as pd

df1 = pd.DataFrame({
    'Number of Iterations': [2000, 5000, 10000],
    'Training Error Rate': ['0.016', '0.011', '0.001'],
    'Training Accuracy': ['0.984', '0.989', '0.999'],
    'Test Error Rate': ['0.057', '0.066', '0.059'],
    'Test Accuracy': ['0.943', '0.934', '0.941']
})

df2 = pd.DataFrame({
    'Number of Hidden Units': [30, 50, 100],
    'Training Error Rate': ['0.036', '0.033', '0.03'],
    'Training Accuracy': ['0.964', '0.967', '0.97'],
    'Test Error Rate': ['0.079', '0.074', '0.077'],
    'Test Accuracy': ['0.921', '0.926', '0.923']
})

df3 = pd.DataFrame({
    'Learning Rate': [0.001, 0.005, 0.01],
    'Training Error Rate': ['0.078', '0.036', '0.039'],
    'Training Accuracy': ['0.922', '0.964', '0.961'],
    'Test Error Rate': ['0.113', '0.079', '0.082'],
    'Test Accuracy': ['0.887', '0.921', '0.918']
})


styled_df1 = df1.style.set_table_attributes("style='display:inline'").set_caption("Table 1: Impact of Number of Training Iterations").set_table_styles([{
    'selector': ' ',
    'props': [('border', '1px solid black')]
}])

styled_df2 = df2.style.set_table_attributes("style='display:inline'").set_caption("Table 2: Impact of Number of Hidden Units").set_table_styles([{
    'selector': ' ',
    'props': [('border', '1px solid black')]
}])

styled_df3 = df3.style.set_table_attributes("style='display:inline'").set_caption("Table 3: Impact of Learning Rate").set_table_styles([{
    'selector': ' ',
    'props': [('border', '1px solid black')]
}])


display(styled_df1)
display(styled_df2)
display(styled_df3)

"""### Part (a) -- 3 pt
Comment on which of the above changes resulted in the best accuracy on training data? What accuracy were you able to achieve?
"""



"""The change that resulted in the best accuracy on the training data is increasing the "Number of Iterations" to 10,000, which yielded a training accuracy of 0.999.

### Part (b) -- 3 pt


Comment on which of the above changes resulted in the best accuracy on testing data? What accuracy were you able to achieve?
"""



"""The change that resulted in the best accuracy on the test data is increasing the "Number of Iterations" to 2,000, which yielded a test accuracy of 0.943.

### Part (c) -- 4 pt
Which model hyperparameters should you use, the ones from (a) or (b)?
"""



"""I should use the hyperparameters that gave me the best accuracy on the test data, which is option (b) with 2,000 iterations resulting in a test accuracy of 0.943. High accuracy on the training data (as in option a) is not always indicative of a model's ability to generalize well to new, unseen data. A training accuracy of 0.999 may indicate that the model has memorized the training data, rather than learning to generalize from it. This is commonly known as overfitting. In contrast, the test data provides a more unbiased evaluation of the model's performance on unseen data. Therefore, the hyperparameters that yield the highest accuracy on the test set are generally preferred."""